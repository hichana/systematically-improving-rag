{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "Projects have a fixed amount of time/effort available to improve the retrieval pipeline, so you need to prioritize where you spend your effort. You'll want to spend effort on improvements that\n",
    "1. Affect many queries\n",
    "2. Affect queries with room for improvement\n",
    "3. Affect high value queries\n",
    "\n",
    "This notebook shows how to monitor production traffic and identify what areas to improve (focusing on criteria 1 and 2 above).\n",
    "\n",
    "Specifically, we use an LLM to categorize queries into different topics or functionality areas. We can do basic analytics to detect\n",
    "1. Which categories have many queries\n",
    "2. Which categories have measures of low customer satisfaction\n",
    "\n",
    "We could do further analytics to look at how these stats change over time (e.g. as we bring in new types of users).\n",
    "\n",
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'Is this high-speed drill bit set more efficient than the SpeedMax Pro set?',\n",
       "  'product': {'title': 'High-Speed Drill Bit Set',\n",
       "   'description': 'This high-speed drill bit set includes 15 professional-grade bits that are perfect for drilling through wood, metal, and plastic. Made from premium steel, they offer durability and long-lasting performance, ensuring you get the job done efficiently. The organized carrying case keeps your bits secure and makes for easy storage and transport.'},\n",
       "  'thumbs_up': False,\n",
       "  'days_ago': 11},\n",
       " {'question': 'How does the durability of these bits compare to the Titan Drill Bit Set?',\n",
       "  'product': {'title': 'High-Speed Drill Bit Set',\n",
       "   'description': 'This high-speed drill bit set includes 15 professional-grade bits that are perfect for drilling through wood, metal, and plastic. Made from premium steel, they offer durability and long-lasting performance, ensuring you get the job done efficiently. The organized carrying case keeps your bits secure and makes for easy storage and transport.'},\n",
       "  'thumbs_up': False,\n",
       "  'days_ago': 10}]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "import instructor\n",
    "import json\n",
    "from openai import AsyncOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "from question_types import (\n",
    "    UntypedQuestion,\n",
    "    TypedQuestion,\n",
    "    Question,\n",
    "    Product,\n",
    "    QuestionTypes,\n",
    "    question_type_details,\n",
    ")\n",
    "\n",
    "client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "def read_to_question(q: dict) -> UntypedQuestion:\n",
    "    question = Question(text=q[\"question\"])\n",
    "    product = Product(title=q[\"product\"][\"title\"], description=q[\"product\"][\"description\"])\n",
    "    return UntypedQuestion(question=question, product=product, thumbs_up=q[\"thumbs_up\"], days_ago=q[\"days_ago\"])\n",
    "\n",
    "with open(\"prod_questions.json\", \"r\") as f:\n",
    "    prod_questions = json.load(f)\n",
    "    untyped_questions = [read_to_question(q) for q in prod_questions]\n",
    "\n",
    "prod_questions[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classifying Queries\n",
    "\n",
    "The raw query types are defined in `question_types.py`. We include these in our prompt and ask an LLM to categorize each question. We could either categorize each question into a single category or into multiple categories. This example categorizes into a single category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from typing import List\n",
    "\n",
    "class QuestionTypeResponse(BaseModel):\n",
    "    reasoning: str      # For chain of thought reasoning\n",
    "    question_types: List[QuestionTypes]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "async_client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "q_type_explanation_list = [\n",
    "    f\"NAME: {q.title}\\nDESCRIPTION: {q.description}\\nEXAMPLES:\\n`{q.examples[0]}`\\n`{q.examples[1]}`\"\n",
    "    for q in question_type_details.values()\n",
    "]\n",
    "\n",
    "q_type_explanation_str = \"\\n\\n---\\n\\n\".join(q_type_explanation_list)\n",
    "\n",
    "\n",
    "async def categorize_question(\n",
    "    question: UntypedQuestion, semaphore: asyncio.Semaphore = asyncio.Semaphore(1)\n",
    ") -> TypedQuestion:\n",
    "    async with semaphore:\n",
    "        question_text = question.question.text\n",
    "        prompt = f\"\"\"\n",
    "        Classify the attached question into one or two of the following categories:\n",
    "        {', '.join([q.value for q in QuestionTypes])}\n",
    "\n",
    "        Here are descriptions of each category:\n",
    "        {q_type_explanation_str}\n",
    "\n",
    "        Here is the question:\n",
    "        Question: {question_text}\n",
    "\n",
    "        For your context, here the product is on a hardware store website with the following description:\n",
    "        {question.product.description}\n",
    "\n",
    "        Give step-by-step reasoning for why the question belongs in any particular category.\n",
    "        Use your judgment about whether the correct number of categories is one or two.\n",
    "        Then give the category name(s) that are the best fit.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            result = await async_client.chat.completions.create(\n",
    "                model=\"gpt-4o-mini\",\n",
    "                response_model=QuestionTypeResponse,\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            )\n",
    "    \n",
    "            # Discard reasoning and get just the question types\n",
    "            question_types = [QuestionTypes(q_type) for q_type in result.question_types]\n",
    "\n",
    "            # For analytics purposes, let a question show up in multiple categories\n",
    "            return [TypedQuestion(\n",
    "                question=question.question,\n",
    "                question_type=q_type,\n",
    "                product=question.product,\n",
    "                thumbs_up=question.thumbs_up,\n",
    "                days_ago=question.days_ago,\n",
    "            ) for q_type in question_types]\n",
    "        except Exception as e:\n",
    "            print(f\"Error classifying question: {str(e)}\")\n",
    "            return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this for all questions (using async patterns since we have many questions, and our time will be spent primarily waiting for API responses)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async def categorize_questions(max_concurrency: int = 100) -> List[TypedQuestion]:\n",
    "    out = []\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [categorize_question(q, semaphore) for q in untyped_questions]\n",
    "    categorized_questions = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    for cq in categorized_questions:\n",
    "        if not isinstance(cq, Exception):\n",
    "            out.extend(cq)\n",
    "        else:\n",
    "            print(f\"Error categorizing question: {str(cq)}\")\n",
    "    return out\n",
    "\n",
    "\n",
    "categorized_questions = await categorize_questions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analytics\n",
    "\n",
    "Convert the data into a DataFrame and calculate basic statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_type</th>\n",
       "      <th>num_questions</th>\n",
       "      <th>fraction_thumbs_up</th>\n",
       "      <th>count_not_thumbs_up</th>\n",
       "      <th>questions_in_last_week</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Comparison</td>\n",
       "      <td>67</td>\n",
       "      <td>0.10</td>\n",
       "      <td>60</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Materials</td>\n",
       "      <td>46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>37</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Authenticity and counterfeits</td>\n",
       "      <td>43</td>\n",
       "      <td>0.12</td>\n",
       "      <td>38</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Trend</td>\n",
       "      <td>42</td>\n",
       "      <td>0.02</td>\n",
       "      <td>41</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>TypicalPrice</td>\n",
       "      <td>42</td>\n",
       "      <td>0.31</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Country of Origin</td>\n",
       "      <td>40</td>\n",
       "      <td>0.62</td>\n",
       "      <td>15</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Environmental Impact</td>\n",
       "      <td>32</td>\n",
       "      <td>0.12</td>\n",
       "      <td>28</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Compatibility</td>\n",
       "      <td>30</td>\n",
       "      <td>0.77</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Vague</td>\n",
       "      <td>30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Customer Service</td>\n",
       "      <td>29</td>\n",
       "      <td>0.62</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accessories</td>\n",
       "      <td>22</td>\n",
       "      <td>0.32</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Time Sensitive</td>\n",
       "      <td>20</td>\n",
       "      <td>0.05</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Visual</td>\n",
       "      <td>17</td>\n",
       "      <td>0.06</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    question_type  num_questions  fraction_thumbs_up  \\\n",
       "2                      Comparison             67                0.10   \n",
       "7                       Materials             46                0.20   \n",
       "1   Authenticity and counterfeits             43                0.12   \n",
       "9                           Trend             42                0.02   \n",
       "10                   TypicalPrice             42                0.31   \n",
       "4               Country of Origin             40                0.62   \n",
       "6            Environmental Impact             32                0.12   \n",
       "3                   Compatibility             30                0.77   \n",
       "11                          Vague             30                0.60   \n",
       "5                Customer Service             29                0.62   \n",
       "0                     Accessories             22                0.32   \n",
       "8                  Time Sensitive             20                0.05   \n",
       "12                         Visual             17                0.06   \n",
       "\n",
       "    count_not_thumbs_up  questions_in_last_week  \n",
       "2                    60                      14  \n",
       "7                    37                      11  \n",
       "1                    38                      22  \n",
       "9                    41                      11  \n",
       "10                   29                       8  \n",
       "4                    15                      12  \n",
       "6                    28                       5  \n",
       "3                     7                       9  \n",
       "11                   12                       4  \n",
       "5                    11                       7  \n",
       "0                    15                       3  \n",
       "8                    19                       6  \n",
       "12                   16                       6  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def show_question_analytics(categorized_questions: List[TypedQuestion]):\n",
    "    clustered_questions = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"question_text\": q.question.text,\n",
    "            \"question_type\": q.question_type.value,\n",
    "            \"product_title\": q.product.title,\n",
    "            \"thumbs_up\": q.thumbs_up,\n",
    "            \"days_ago\": q.days_ago,\n",
    "        }\n",
    "        for q in categorized_questions\n",
    "        if q is not None\n",
    "    ]\n",
    "    )\n",
    "    \n",
    "    cluster_stats = (\n",
    "    clustered_questions.groupby(\"question_type\")\n",
    "    .agg(\n",
    "        num_questions=(\"question_text\", \"size\"),\n",
    "        fraction_thumbs_up=(\"thumbs_up\", \"mean\"),\n",
    "        count_not_thumbs_up=(\"thumbs_up\", lambda x: x.size - x.sum()),\n",
    "        questions_in_last_week = (\"days_ago\", lambda x: (x <= 7).sum()),\n",
    "    )\n",
    "    .reset_index()\n",
    "    )\n",
    "\n",
    "    return cluster_stats.round(2).sort_values(\"num_questions\", ascending=False)\n",
    "\n",
    "cluster_stats = show_question_analytics(categorized_questions)\n",
    "cluster_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'matplotlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pyplot \u001b[38;5;28;01mas\u001b[39;00m plt\n\u001b[1;32m      2\u001b[0m plt\u001b[38;5;241m.\u001b[39mstyle\u001b[38;5;241m.\u001b[39muse(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfivethirtyeight\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mplot_review_fractions\u001b[39m(df):\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'matplotlib'"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "plt.style.use('fivethirtyeight')\n",
    "\n",
    "def plot_review_fractions(df):\n",
    "    total_reviews = df['num_questions'].sum()\n",
    "    total_reviews_last_week = df['questions_in_last_week'].sum()\n",
    "\n",
    "    df['fraction_reviews'] = df['num_questions'] / total_reviews\n",
    "    df['fraction_reviews_last_week'] = df['questions_in_last_week'] / total_reviews_last_week\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(10, 8))\n",
    "\n",
    "    width = 0.35\n",
    "    x = range(len(df))\n",
    "\n",
    "    ax.bar(x, df['fraction_reviews'], width, label='Total Reviews', color='skyblue')\n",
    "    ax.bar([p + width for p in x], df['fraction_reviews_last_week'], width, label='Last Week Reviews', color='lightgreen')\n",
    "\n",
    "    ax.set_xlabel('Question Type')\n",
    "    ax.set_ylabel('Fraction of Reviews')\n",
    "    ax.set_title('Fraction of Reviews by Question Type')\n",
    "    ax.set_xticks([p + width/2 for p in x])\n",
    "    ax.set_xticklabels(df['question_type'], rotation=45, ha='right')\n",
    "    ax.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "plot_review_fractions(cluster_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "What areas would you prioritize?\n",
    "\n",
    "Some candidates:\n",
    "- Allow combining reviews across products since cross-product comparisons are common and poorly served (biggest source of thumbs down)\n",
    "- If you run a platform with many sellers (e.g. Amazon), allow filtering by seller within a given SKU. This may help address `Counterfeits`. It is common, poorly served, and is getting more common\n",
    "- Materials is also a major source of thumbs down. If you have that data, you might consider adding it even though it's not in reviews\n",
    "\n",
    "\n",
    "Exact prioritization depends on how much effort each potential improvement requires, how effective you expect it to be, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
