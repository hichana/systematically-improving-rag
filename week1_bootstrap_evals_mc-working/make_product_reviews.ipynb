{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Context\n",
    "\n",
    "This code relates to building a feature that extracts a list of entities and entity metadata for an app from documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 3 unique objects\n",
      "First 10 objects: [Document(title='Project Update Email', content='**Subject:** Project Update: Phase 2 Progress\\n\\nDear Team,\\n\\nI hope this message finds you well. I wanted to share a quick update on the progress of Phase 2 of our project. Currently, we are on track to complete the initial stages by the end of this month. \\n\\n### Key Highlights:\\n- **Milestone 1** completed: All user requirements have been gathered.\\n- **Milestone 2** in progress: Development team is working on the features.\\n\\n### Next Steps:\\nPlease ensure that you complete your respective tasks and provide your input for the upcoming review meeting scheduled for next week.\\n\\nBest regards,\\n\\nJohn Doe  \\nProject Manager'), Document(title='Team Chat Discussion', content=\"**Team Chat – Project Coordination**  \\n**Date:** October 10, 2023  \\n\\n**John:** Just a reminder that the review meeting is on Friday. Let's aim to finalize our tasks by then.  \\n**Emily:** I’m still working on Milestone 2. Should we extend the deadline since we’re running behind?  \\n**John:** No, let's stick to the original timeline for now. We need to stay on track for the project launch next month.  \\n**Michael:** I agree with John. Meeting the original deadlines is crucial for our schedule.\\n\\nLet’s keep the momentum going!\"), Document(title='Internal Memo on Project Deadlines', content='**TO:** All Teams  \\n**FROM:** Management  \\n**DATE:** October 10, 2023  \\n**SUBJECT:** Update on Project Deadlines\\n\\nAttention Team,\\n\\nPlease be advised that due to recent delays in Phase 2, we have decided to extend the deadline by two weeks. The new target for completing all milestones will now be November 15, 2023.\\n\\n### Changes Overview:\\n- **Original Deadline:** October 31, 2023\\n- **New Deadline:** November 15, 2023\\n\\nThis extension will ensure we maintain the quality of deliverables. \\n\\nThanks for your understanding and cooperation.  \\n\\nBest,  \\nManagement Team')]\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from typing import List\n",
    "import instructor\n",
    "import json\n",
    "import lancedb\n",
    "from lancedb.embeddings import get_registry\n",
    "from lancedb.pydantic import LanceModel, Vector\n",
    "from openai import AsyncOpenAI, OpenAI\n",
    "from pydantic import BaseModel\n",
    "\n",
    "client = instructor.from_openai(OpenAI())\n",
    "\n",
    "\n",
    "class Document(BaseModel):\n",
    "    title: str\n",
    "    content: str\n",
    "\n",
    "\n",
    "def generate_physical_objects(n_objects: int = 3) -> List[Document]:\n",
    "    prompt = (\n",
    "        f\"Create a list of {n_objects} documents someone might be interacting with in the workplace, like email, chat or a memo.\\n\"\n",
    "    )\n",
    "    prompt += \"The content of the documents may share similar entities, themes and some content, but each document title and content must be unique.\\n\"\n",
    "    prompt += \"Contradicting information between one document and another related one, like in an email and a memo, is ok only to the extent you would expect that in real data.\"\n",
    "    prompt += \"Respond only with the list of documents and their content.\"\n",
    "    prompt += \"If a document would likely contain things like headings and rich text formatting, be sure to add such content formatted in markdown.\"\n",
    "\n",
    "    try:\n",
    "        objects = client.chat.completions.create(\n",
    "            model=\"gpt-4o-mini\",\n",
    "            response_model=List[Document],\n",
    "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        )\n",
    "        return objects\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating evals: {str(e)}\")\n",
    "        return []\n",
    "\n",
    "\n",
    "objects = generate_physical_objects()\n",
    "print(f\"Created {len(objects)} unique objects\")\n",
    "print(f\"First 10 objects: {objects[:10]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chunk all documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch the AsyncOpenAI client\n",
    "async_client = instructor.from_openai(AsyncOpenAI())\n",
    "\n",
    "\n",
    "class Review(BaseModel):\n",
    "    review: str\n",
    "\n",
    "\n",
    "class AllObjectInfo(BaseModel):\n",
    "    product_title: str\n",
    "    product_description: str\n",
    "    review: str\n",
    "\n",
    "\n",
    "async def make_reviews(\n",
    "    product: Product, n: int, semaphore: asyncio.Semaphore = asyncio.Semaphore(1)\n",
    ") -> List[AllObjectInfo]:\n",
    "    async with semaphore:\n",
    "        prompt = f\"\"\"\n",
    "        Write {n} realistic but detailed/specific product reviews that might show up on a hardware store's website.\n",
    "\n",
    "        The reviews should be about the following product:\n",
    "        Product Title: {product.title}\n",
    "        Product Description: {product.description}\n",
    "        \n",
    "        Add many relevant and concrete facts about the products (this is for synthetic data generation, make up facts about each product as necessary).\n",
    "\n",
    "        To see the format of a possible review, here is a review for a saw:\n",
    "        ```\n",
    "        I've enjoyed using this saw. It is lightweight and the battery lasts longer than other brands.\n",
    "        I've been using it for 3 years now and it has been very durable. It was twice as expensive as the PX-500. But\n",
    "        it is comfortable to hold because of the light weight.\n",
    "        ```\n",
    "\n",
    "        Respond only with the reviews, and nothing else.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            result = await async_client.chat.completions.create(\n",
    "                model=\"gpt-4o\",\n",
    "                response_model=List[Review],\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "            )\n",
    "            return [\n",
    "                AllObjectInfo(\n",
    "                    product_title=product.title,\n",
    "                    product_description=product.description,\n",
    "                    review=r.review,\n",
    "                )\n",
    "                for r in result\n",
    "            ]\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating FreeCAD code: {str(e)}\")\n",
    "            return []\n",
    "\n",
    "\n",
    "async def create_synthetic_reviews(\n",
    "    max_concurrency: int = 20, reviews_per_product: int = reviews_per_product\n",
    ") -> List[AllObjectInfo]:\n",
    "    out = []\n",
    "    semaphore = asyncio.Semaphore(max_concurrency)\n",
    "    tasks = [make_reviews(o, reviews_per_product, semaphore) for o in objects]\n",
    "    results = await asyncio.gather(*tasks, return_exceptions=True)\n",
    "    for r in results:\n",
    "        if not isinstance(r, Exception):\n",
    "            out.extend(r)\n",
    "    return out\n",
    "\n",
    "\n",
    "reviews = await create_synthetic_reviews()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store the items to be retrieved in LanceDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-08-07T07:20:04Z WARN  lance::dataset] No existing dataset at /Users/matthewchana/Documents/systematically-improving-rag/week1_bootstrap_evals/lancedb/products.lance, it will be created\n",
      "[2024-08-07T07:20:06Z WARN  lance::dataset] No existing dataset at /Users/matthewchana/Documents/systematically-improving-rag/week1_bootstrap_evals/lancedb/reviews.lance, it will be created\n"
     ]
    }
   ],
   "source": [
    "db = lancedb.connect(\"./lancedb\")\n",
    "func = get_registry().get(\"openai\").create(name=\"text-embedding-3-small\")\n",
    "\n",
    "\n",
    "class Products(LanceModel):\n",
    "    id: str = func.SourceField()\n",
    "    title: str = func.SourceField()\n",
    "    description: str = func.SourceField()\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "\n",
    "\n",
    "products_table = db.create_table(\"products\", schema=Products, mode=\"overwrite\")\n",
    "products_data = [\n",
    "    {\"id\": f\"{i}\", \"title\": obj.title, \"description\": obj.description}\n",
    "    for i, obj in enumerate(objects)\n",
    "]\n",
    "products_table.add(products_data)\n",
    "products_table.create_fts_index(\"description\", replace=True)\n",
    "product_id_map = {\n",
    "    p[\"title\"]: p[\"id\"] for p in products_table.to_pandas().to_dict(\"records\")\n",
    "}\n",
    "\n",
    "\n",
    "class Reviews(LanceModel):\n",
    "    id: str = func.SourceField()\n",
    "    product_title: str = func.SourceField()\n",
    "    product_description: str = func.SourceField()\n",
    "    review: str = func.SourceField()\n",
    "    vector: Vector(func.ndims()) = func.VectorField()\n",
    "\n",
    "\n",
    "reviews_table = db.create_table(\"reviews\", schema=Reviews, mode=\"overwrite\")\n",
    "\n",
    "reviews_with_product_id = [\n",
    "    {\n",
    "        \"id\": f\"{i}\",\n",
    "        \"product_title\": review.product_title,\n",
    "        \"product_description\": review.product_description,\n",
    "        \"review\": review.review,\n",
    "    }\n",
    "    for i, review in enumerate(reviews)\n",
    "]\n",
    "reviews_table.add(reviews_with_product_id)\n",
    "reviews_table.create_fts_index(\"review\", replace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In case you want to see the data quickly in a text editor, we also store the data in JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./reviews.json\", \"w\") as f:\n",
    "    json.dump([i.dict() for i in reviews], f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
